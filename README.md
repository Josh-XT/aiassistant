# AI Assistant

AI Assistant is a FastAPI-powered web application that provides an interface for interacting with a GPT-based language model using the [Llama.cpp](https://github.com/ggerganov/llama.cpp) library. The application allows users to send questions to the AI Assistant, which will return answers generated by the underlying language model.

During the initial setup, AI Assistant automatically downloads and configures the Llama.cpp repository, as well as the required models and weights.

## Features

- FastAPI-based web application for easy interaction with the AI Assistant
- Utilizes the Llama.cpp library for efficient language model execution
- Supports different model sizes (7, 13, 30, and 65 billion parameters)
- Dockerized application for easy deployment and portability
- Configurable model size via environment variable
- Automatic download and configuration of Llama.cpp and required models

## Requirements

- Docker and Docker Compose
- Python 3.8 or later

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/ai-assistant.git
   cd ai-assistant

2. Build and run the Docker container using Docker Compose:

```
docker-compose up -d
```

This will build the Docker image, create the necessary volumes, and start the AI Assistant service on port 5437.

3. Access the AI Assistant API at http://localhost:5437.

## Usage
To interact with the AI Assistant, send an HTTP GET request to the /chat endpoint with the email and question query parameters.

Example:

```
http://localhost:5437/chat?email=johndoe@example.com&question=What%20is%20the%20speed%20of%20light%3F
```

The API will return a JSON object containing the AI Assistant's response:
```
{
  "response": "The speed of light in a vacuum is approximately 299,792 kilometers per second (186,282 miles per second). This constant is denoted by the letter 'c' and is a fundamental constant in physics."
}
```

## Customization
To use a different model size, update the MODEL_SIZE environment variable in the docker-compose.yml file to the desired value (7, 13, 30, or 65). Then, rebuild and restart the container:

```
docker-compose up -d --build
```
